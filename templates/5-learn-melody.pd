#N canvas 827 239 734 565 12;
#X declare -path drumcode/pd;
#X obj 58 239 adc~ 1;
#X text 123 262 select input 1 from the soundcard;
#X obj 58 298 meter~;
#X text 123 297 the [meter~] gives the volume measure of the input, f 25;
#X obj 58 476 dc.trigger~;
#X text 141 475 use this object to detect triggers from the sound;
#X obj 146 395 hsl 128 17 0 1 0 1 empty empty empty -2 -8 0 10 #e4e4e4 #4d4d4d #000000 3692 1;
#X text 306 431 adjust the gate (-60 - 0dB) \, sound below this level is not detected, f 31;
#X obj 170 432 hsl 128 17 -60 0 0 1 empty empty empty -2 -8 0 10 #e4e4e4 #4d4d4d #000000 4074 1;
#X obj 58 59 cnv 15 421 41 empty empty ./drum.code\ -\ Getting\ Started\ 5 20 20 0 24 #00cb9e #ffffff 0;
#X text 498 58 Written by Timo Hoogland \, 2024 \, www.timohoogland.com;
#X text 498 78 License: GNU GPL-3.0;
#X text 498 98 Funded by Creative Industries Fund NL;
#X obj 58 518 bng 25 250 50 0 empty empty empty 17 7 0 10 #e4e4e4 #4d4d4d #000000;
#X text 92 517 display the trigger with a button;
#X obj 58 1097 dac~ 1 2;
#X text 137 1096 send sound to the speaker output;
#X text 137 1119 dac = Digital -> Analog Converter;
#X text 123 238 adc = Analog -> Digital Converter;
#X obj 92 801 hsl 128 17 0 127 0 1 empty empty empty -2 -8 0 10 #e4e4e4 #4d4d4d #000000 8000 1;
#X text 233 800 adjust the note length;
#X obj 501 819 hsl 128 17 0 127 0 1 empty empty empty -2 -8 0 10 #e4e4e4 #4d4d4d #000000 8000 1;
#X text 642 818 adjust the distortion;
#X text 498 214 Don't delete! This is needed to be able to use the [dc.*] objects;
#X obj 58 109 cnv 15 421 31 empty empty Generating\ Notes\ with\ "Machine\ Learning" 20 14 0 20 #838383 #ffffff 0;
#X text 140 375 adjust the [hslider] to change trigger sensitivity;
#X obj 498 280 dc.audio.onoff~;
#X text 638 280 [dc.audio.onoff~] object transforms into this user interface to turn on/off the sound, f 29;
#X obj 498 239 declare -path drumcode/pd;
#X obj 58 863 dc.synth~;
#X text 58 153 In this template we can see how we use a list of values to train a small machine learning algorithm in the object [dc.learn]. Then every time it receives a trigger it will predict the next value that is most likely to come after the previous value and output it.;
#X obj 58 758 dc.learn;
#X obj 106 609 loadbang;
#X text 179 608 the melody below is trained when the patch starts;
#X text 130 757 <- learns from the melody and outputs a note every time it gets a trigger, f 35;
#X obj 498 758 dc.learn;
#X obj 545 671 loadbang;
#X obj 58 558 trigger bang bang;
#X obj 441 558 t b b;
#X text 179 557 we create 2 triggers from 1 trigger (short:);
#X msg 545 702 20 20 80 20 80 100 60 40;
#X text 570 757 <- learns from the distortion amount pattern and outputs a value every time it gets a trigger, f 35;
#X text 624 670 a sequence of distortion values;
#X msg 106 640 60 62 63 60 60 62 63 60 63 65 67 63 65 67;
#X msg 130 702 67 68 67 65 63 60 67 68 67 65 63 60 60 59 60 60 59 60;
#X text 130 678 when clicking this the melody is added to the training;
#X obj 88 914 dc.fx.reverb~;
#X obj 63 970 gain2~ 1 0 20 0 0.803681;
#A saved;
#X text 187 913 a stereo reverb effect;
#X text 137 969 a [gain2~] slider to control the sound output;
#X obj 581 510 note2midi;
#X msg 581 476 C4 D4 D#4 C4 C4 D4 D#4 C4 D#4 F4 G4 Eb4 F4 G4;
#X text 660 509 use note2midi if you want to specify the list with notenames instead of MIDI numbers, f 38;
#X obj 581 543 dc.learn;
#X text 581 450 EXTRA;
#X connect 0 0 2 0;
#X connect 2 0 4 0;
#X connect 4 0 13 0;
#X connect 6 0 4 1;
#X connect 8 0 4 3;
#X connect 13 0 37 0;
#X connect 19 0 29 2;
#X connect 21 0 29 3;
#X connect 29 0 46 0;
#X connect 29 0 47 0;
#X connect 29 0 47 1;
#X connect 31 0 29 0;
#X connect 32 0 43 0;
#X connect 35 0 21 0;
#X connect 36 0 40 0;
#X connect 37 0 31 0;
#X connect 37 1 35 0 32.................T....nT....E....JE...nG....;
#X connect 40 0 35 1;
#X connect 43 0 31 1;
#X connect 44 0 31 2;
#X connect 46 0 47 0;
#X connect 46 1 47 1;
#X connect 47 0 15 0;
#X connect 47 1 15 1;
#X connect 50 0 53 1;
#X connect 51 0 50 0;
